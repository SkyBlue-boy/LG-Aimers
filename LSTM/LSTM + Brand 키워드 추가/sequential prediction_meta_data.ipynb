{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T08:38:28.943727Z",
     "start_time": "2023-08-03T08:38:27.704132Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T08:38:28.963134Z",
     "start_time": "2023-08-03T08:38:28.945970Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T08:38:29.389863Z",
     "start_time": "2023-08-03T08:38:29.385313Z"
    }
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'TRAIN_WINDOW_SIZE':90, # 90일치로 학습\n",
    "    'PREDICT_SIZE':21, # 21일치 예측\n",
    "    'EPOCHS':10,\n",
    "    'LEARNING_RATE':1e-4,\n",
    "    'BATCH_SIZE':4096,\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T08:38:31.512962Z",
     "start_time": "2023-08-03T08:38:31.505665Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T08:38:33.674479Z",
     "start_time": "2023-08-03T08:38:32.945675Z"
    }
   },
   "outputs": [],
   "source": [
    "brand_keyword = pd.read_csv('data/brand_keyword_cnt.csv')\n",
    "product_info = pd.read_csv('data/product_info.csv')\n",
    "sales = pd.read_csv('data/sales.csv')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T08:38:37.914521Z",
     "start_time": "2023-08-03T08:38:37.441322Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train.csv').drop(columns=['제품'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T04:29:14.507858Z",
     "start_time": "2023-08-03T04:29:14.490062Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>대분류</th>\n",
       "      <th>중분류</th>\n",
       "      <th>소분류</th>\n",
       "      <th>브랜드</th>\n",
       "      <th>2022-01-01</th>\n",
       "      <th>2022-01-02</th>\n",
       "      <th>2022-01-03</th>\n",
       "      <th>2022-01-04</th>\n",
       "      <th>2022-01-05</th>\n",
       "      <th>...</th>\n",
       "      <th>2023-03-26</th>\n",
       "      <th>2023-03-27</th>\n",
       "      <th>2023-03-28</th>\n",
       "      <th>2023-03-29</th>\n",
       "      <th>2023-03-30</th>\n",
       "      <th>2023-03-31</th>\n",
       "      <th>2023-04-01</th>\n",
       "      <th>2023-04-02</th>\n",
       "      <th>2023-04-03</th>\n",
       "      <th>2023-04-04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0007</td>\n",
       "      <td>B002-C003-0038</td>\n",
       "      <td>B002-00001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-00002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-00002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-00002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B002-C001-0001</td>\n",
       "      <td>B002-C002-0001</td>\n",
       "      <td>B002-C003-0003</td>\n",
       "      <td>B002-00003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 464 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID             대분류             중분류             소분류         브랜드  2022-01-01  \\\n",
       "0   0  B002-C001-0002  B002-C002-0007  B002-C003-0038  B002-00001           0   \n",
       "1   1  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-00002           0   \n",
       "2   2  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-00002           0   \n",
       "3   3  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-00002           0   \n",
       "4   4  B002-C001-0001  B002-C002-0001  B002-C003-0003  B002-00003           0   \n",
       "\n",
       "   2022-01-02  2022-01-03  2022-01-04  2022-01-05  ...  2023-03-26  \\\n",
       "0           0           0           0           0  ...           0   \n",
       "1           0           0           0           0  ...           0   \n",
       "2           0           0           0           0  ...           0   \n",
       "3           0           0           0           0  ...           0   \n",
       "4           0           0           0           0  ...           0   \n",
       "\n",
       "   2023-03-27  2023-03-28  2023-03-29  2023-03-30  2023-03-31  2023-04-01  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           1           3           2           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   2023-04-02  2023-04-03  2023-04-04  \n",
       "0           0           0           0  \n",
       "1           0           2           0  \n",
       "2           0           0           0  \n",
       "3           0           0           0  \n",
       "4           0           0           0  \n",
       "\n",
       "[5 rows x 464 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T04:29:15.887405Z",
     "start_time": "2023-08-03T04:29:15.880445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[95,\n",
       " 246,\n",
       " 250,\n",
       " 303,\n",
       " 385,\n",
       " 440,\n",
       " 444,\n",
       " 466,\n",
       " 515,\n",
       " 647,\n",
       " 765,\n",
       " 811,\n",
       " 1105,\n",
       " 1162,\n",
       " 1398,\n",
       " 1486,\n",
       " 1518,\n",
       " 1588,\n",
       " 1706,\n",
       " 1893,\n",
       " 1980,\n",
       " 1999,\n",
       " 2117,\n",
       " 2125,\n",
       " 2298,\n",
       " 2328,\n",
       " 2349,\n",
       " 2430,\n",
       " 2471,\n",
       " 2495,\n",
       " 2529,\n",
       " 2711,\n",
       " 2855,\n",
       " 3142,\n",
       " 3149]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nullrow = brand_keyword['2022-01-01'][brand_keyword['2022-01-01'].isnull()]\n",
    "\n",
    "nullrow = list(nullrow.index)\n",
    "nullrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T04:29:17.740882Z",
     "start_time": "2023-08-03T04:29:17.729507Z"
    }
   },
   "outputs": [],
   "source": [
    "brand_keyword.drop('브랜드', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T04:29:17.965329Z",
     "start_time": "2023-08-03T04:29:17.937918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3160</th>\n",
       "      <th>3161</th>\n",
       "      <th>3162</th>\n",
       "      <th>3163</th>\n",
       "      <th>3164</th>\n",
       "      <th>3165</th>\n",
       "      <th>3166</th>\n",
       "      <th>3167</th>\n",
       "      <th>3168</th>\n",
       "      <th>3169</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>0.84131</td>\n",
       "      <td>12.64868</td>\n",
       "      <td>0.33362</td>\n",
       "      <td>1.07339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.884820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232064</td>\n",
       "      <td>0.33362</td>\n",
       "      <td>4.33710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.07020</td>\n",
       "      <td>2.77052</td>\n",
       "      <td>1.07339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.32085</td>\n",
       "      <td>0.14505</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.14505</td>\n",
       "      <td>4.55468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02</th>\n",
       "      <td>0.91383</td>\n",
       "      <td>20.27850</td>\n",
       "      <td>0.43516</td>\n",
       "      <td>1.71163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.624588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.246574</td>\n",
       "      <td>0.44966</td>\n",
       "      <td>6.38236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.44995</td>\n",
       "      <td>3.64084</td>\n",
       "      <td>1.34899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.98810</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.54105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>1.45053</td>\n",
       "      <td>15.33217</td>\n",
       "      <td>0.36263</td>\n",
       "      <td>2.01624</td>\n",
       "      <td>0.188558</td>\n",
       "      <td>1.914691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.464151</td>\n",
       "      <td>0.55120</td>\n",
       "      <td>6.61444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.64026</td>\n",
       "      <td>4.90281</td>\n",
       "      <td>1.53756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.61183</td>\n",
       "      <td>0.08703</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.11604</td>\n",
       "      <td>6.15027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "      <td>2.42239</td>\n",
       "      <td>12.75021</td>\n",
       "      <td>0.17406</td>\n",
       "      <td>1.91470</td>\n",
       "      <td>0.246574</td>\n",
       "      <td>1.697114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377139</td>\n",
       "      <td>0.52219</td>\n",
       "      <td>6.29532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.11633</td>\n",
       "      <td>6.45488</td>\n",
       "      <td>1.18944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.06150</td>\n",
       "      <td>0.07252</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.07252</td>\n",
       "      <td>6.39686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <td>1.87119</td>\n",
       "      <td>13.56251</td>\n",
       "      <td>0.21758</td>\n",
       "      <td>1.98723</td>\n",
       "      <td>0.246574</td>\n",
       "      <td>1.595591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.580207</td>\n",
       "      <td>0.47867</td>\n",
       "      <td>6.19379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.60951</td>\n",
       "      <td>5.74412</td>\n",
       "      <td>1.40702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.66985</td>\n",
       "      <td>0.08703</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.11604</td>\n",
       "      <td>7.00609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31</th>\n",
       "      <td>0.29010</td>\n",
       "      <td>9.48651</td>\n",
       "      <td>0.49318</td>\n",
       "      <td>1.53756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.928326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.667242</td>\n",
       "      <td>2.61096</td>\n",
       "      <td>6.16478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.03162</td>\n",
       "      <td>3.23469</td>\n",
       "      <td>2.04525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.98723</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.11604</td>\n",
       "      <td>5.51203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-01</th>\n",
       "      <td>0.31911</td>\n",
       "      <td>9.28343</td>\n",
       "      <td>0.91383</td>\n",
       "      <td>1.34899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.928326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261084</td>\n",
       "      <td>2.50942</td>\n",
       "      <td>6.62895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.72787</td>\n",
       "      <td>2.65448</td>\n",
       "      <td>1.87119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.07339</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.11604</td>\n",
       "      <td>3.52480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-02</th>\n",
       "      <td>0.23208</td>\n",
       "      <td>10.42935</td>\n",
       "      <td>0.79779</td>\n",
       "      <td>1.26196</td>\n",
       "      <td>0.072526</td>\n",
       "      <td>0.884820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.348119</td>\n",
       "      <td>0.94284</td>\n",
       "      <td>7.25268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.77139</td>\n",
       "      <td>2.93008</td>\n",
       "      <td>3.20568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.92921</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.08703</td>\n",
       "      <td>4.03249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03</th>\n",
       "      <td>0.33362</td>\n",
       "      <td>11.15462</td>\n",
       "      <td>1.01537</td>\n",
       "      <td>2.32085</td>\n",
       "      <td>0.217577</td>\n",
       "      <td>1.392500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.812294</td>\n",
       "      <td>0.92834</td>\n",
       "      <td>7.74586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.51029</td>\n",
       "      <td>4.33710</td>\n",
       "      <td>3.22019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.50942</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.07252</td>\n",
       "      <td>0.17406</td>\n",
       "      <td>5.88917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-04</th>\n",
       "      <td>0.44966</td>\n",
       "      <td>11.38671</td>\n",
       "      <td>0.88482</td>\n",
       "      <td>2.30635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.203943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.696239</td>\n",
       "      <td>1.84218</td>\n",
       "      <td>6.94807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.27908</td>\n",
       "      <td>4.14853</td>\n",
       "      <td>2.94458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.78416</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.07252</td>\n",
       "      <td>0.10153</td>\n",
       "      <td>5.07687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>459 rows × 3170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1        2        3         4         5     6     \\\n",
       "2022-01-01  0.84131  12.64868  0.33362  1.07339  0.000000  0.884820   0.0   \n",
       "2022-01-02  0.91383  20.27850  0.43516  1.71163  0.000000  1.624588   0.0   \n",
       "2022-01-03  1.45053  15.33217  0.36263  2.01624  0.188558  1.914691   0.0   \n",
       "2022-01-04  2.42239  12.75021  0.17406  1.91470  0.246574  1.697114   0.0   \n",
       "2022-01-05  1.87119  13.56251  0.21758  1.98723  0.246574  1.595591   0.0   \n",
       "...             ...       ...      ...      ...       ...       ...   ...   \n",
       "2023-03-31  0.29010   9.48651  0.49318  1.53756  0.000000  0.928326   0.0   \n",
       "2023-04-01  0.31911   9.28343  0.91383  1.34899  0.000000  0.928326   0.0   \n",
       "2023-04-02  0.23208  10.42935  0.79779  1.26196  0.072526  0.884820   0.0   \n",
       "2023-04-03  0.33362  11.15462  1.01537  2.32085  0.217577  1.392500   0.0   \n",
       "2023-04-04  0.44966  11.38671  0.88482  2.30635  0.000000  1.203943   0.0   \n",
       "\n",
       "                7        8        9     ...  3160      3161     3162     3163  \\\n",
       "2022-01-01  0.232064  0.33362  4.33710  ...   0.0  14.07020  2.77052  1.07339   \n",
       "2022-01-02  0.246574  0.44966  6.38236  ...   0.0  17.44995  3.64084  1.34899   \n",
       "2022-01-03  0.464151  0.55120  6.61444  ...   0.0  19.64026  4.90281  1.53756   \n",
       "2022-01-04  0.377139  0.52219  6.29532  ...   0.0  17.11633  6.45488  1.18944   \n",
       "2022-01-05  0.580207  0.47867  6.19379  ...   0.0  17.60951  5.74412  1.40702   \n",
       "...              ...      ...      ...  ...   ...       ...      ...      ...   \n",
       "2023-03-31  0.667242  2.61096  6.16478  ...   0.0   3.03162  3.23469  2.04525   \n",
       "2023-04-01  0.261084  2.50942  6.62895  ...   0.0   3.72787  2.65448  1.87119   \n",
       "2023-04-02  0.348119  0.94284  7.25268  ...   0.0   3.77139  2.93008  3.20568   \n",
       "2023-04-03  0.812294  0.92834  7.74586  ...   0.0   3.51029  4.33710  3.22019   \n",
       "2023-04-04  0.696239  1.84218  6.94807  ...   0.0   4.27908  4.14853  2.94458   \n",
       "\n",
       "            3164     3165     3166     3167     3168     3169  \n",
       "2022-01-01   0.0  2.32085  0.14505  0.00000  0.14505  4.55468  \n",
       "2022-01-02   0.0  2.98810  0.00000  0.00000  0.00000  5.54105  \n",
       "2022-01-03   0.0  3.61183  0.08703  0.00000  0.11604  6.15027  \n",
       "2022-01-04   0.0  4.06150  0.07252  0.00000  0.07252  6.39686  \n",
       "2022-01-05   0.0  3.66985  0.08703  0.00000  0.11604  7.00609  \n",
       "...          ...      ...      ...      ...      ...      ...  \n",
       "2023-03-31   0.0  1.98723  0.00000  0.00000  0.11604  5.51203  \n",
       "2023-04-01   0.0  1.07339  0.00000  0.00000  0.11604  3.52480  \n",
       "2023-04-02   0.0  1.92921  0.00000  0.00000  0.08703  4.03249  \n",
       "2023-04-03   0.0  2.50942  0.00000  0.07252  0.17406  5.88917  \n",
       "2023-04-04   0.0  1.78416  0.00000  0.07252  0.10153  5.07687  \n",
       "\n",
       "[459 rows x 3170 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_t = brand_keyword.T\n",
    "brand_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T04:29:19.852811Z",
     "start_time": "2023-08-03T04:29:19.849428Z"
    }
   },
   "outputs": [],
   "source": [
    "# 브랜드 별로 keyword cnt trend확인\n",
    "#for i in brand_t.columns:\n",
    "#    brand_t[i].plot(figsize = (10,6))\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T04:29:20.055347Z",
     "start_time": "2023-08-03T04:29:20.050174Z"
    }
   },
   "outputs": [],
   "source": [
    "null_brand = brand_t[nullrow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T04:29:20.521794Z",
     "start_time": "2023-08-03T04:29:20.513757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95      459\n",
       "246     459\n",
       "250     459\n",
       "303     459\n",
       "385     459\n",
       "440     459\n",
       "444     459\n",
       "466     459\n",
       "515     459\n",
       "647     459\n",
       "765     459\n",
       "811     459\n",
       "1105    459\n",
       "1162    459\n",
       "1398    459\n",
       "1486    459\n",
       "1518    459\n",
       "1588    459\n",
       "1706    459\n",
       "1893    459\n",
       "1980    459\n",
       "1999    459\n",
       "2117    459\n",
       "2125    459\n",
       "2298    459\n",
       "2328    459\n",
       "2349    459\n",
       "2430    459\n",
       "2471    459\n",
       "2495    459\n",
       "2529    459\n",
       "2711    459\n",
       "2855    459\n",
       "3142    459\n",
       "3149    459\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측이 있는 브랜드는 아예 측정이 안됨 모든 시점이 결측치임. \n",
    "null_brand.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T04:29:21.251418Z",
     "start_time": "2023-08-03T04:29:21.049466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_keyword = pd.read_csv('data/brand_keyword_cnt.csv')\n",
    "brand_keyword = brand_keyword.fillna(0)\n",
    "brand_keyword.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T04:29:25.445461Z",
     "start_time": "2023-08-03T04:29:25.418690Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>브랜드</th>\n",
       "      <th>2022-01-01</th>\n",
       "      <th>2022-01-02</th>\n",
       "      <th>2022-01-03</th>\n",
       "      <th>2022-01-04</th>\n",
       "      <th>2022-01-05</th>\n",
       "      <th>2022-01-06</th>\n",
       "      <th>2022-01-07</th>\n",
       "      <th>2022-01-08</th>\n",
       "      <th>2022-01-09</th>\n",
       "      <th>...</th>\n",
       "      <th>2023-03-26</th>\n",
       "      <th>2023-03-27</th>\n",
       "      <th>2023-03-28</th>\n",
       "      <th>2023-03-29</th>\n",
       "      <th>2023-03-30</th>\n",
       "      <th>2023-03-31</th>\n",
       "      <th>2023-04-01</th>\n",
       "      <th>2023-04-02</th>\n",
       "      <th>2023-04-03</th>\n",
       "      <th>2023-04-04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>B002-00117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>B002-00296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>B002-00302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>B002-00366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>B002-00460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 460 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            브랜드  2022-01-01  2022-01-02  2022-01-03  2022-01-04  2022-01-05  \\\n",
       "95   B002-00117         0.0         0.0         0.0         0.0         0.0   \n",
       "246  B002-00296         0.0         0.0         0.0         0.0         0.0   \n",
       "250  B002-00302         0.0         0.0         0.0         0.0         0.0   \n",
       "303  B002-00366         0.0         0.0         0.0         0.0         0.0   \n",
       "385  B002-00460         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "     2022-01-06  2022-01-07  2022-01-08  2022-01-09  ...  2023-03-26  \\\n",
       "95          0.0         0.0         0.0         0.0  ...         0.0   \n",
       "246         0.0         0.0         0.0         0.0  ...         0.0   \n",
       "250         0.0         0.0         0.0         0.0  ...         0.0   \n",
       "303         0.0         0.0         0.0         0.0  ...         0.0   \n",
       "385         0.0         0.0         0.0         0.0  ...         0.0   \n",
       "\n",
       "     2023-03-27  2023-03-28  2023-03-29  2023-03-30  2023-03-31  2023-04-01  \\\n",
       "95          0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "246         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "250         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "303         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "385         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "     2023-04-02  2023-04-03  2023-04-04  \n",
       "95          0.0         0.0         0.0  \n",
       "246         0.0         0.0         0.0  \n",
       "250         0.0         0.0         0.0  \n",
       "303         0.0         0.0         0.0  \n",
       "385         0.0         0.0         0.0  \n",
       "\n",
       "[5 rows x 460 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0으로 대체\n",
    "brand_keyword.iloc[nullrow,:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T04:30:18.816548Z",
     "start_time": "2023-08-03T04:30:18.561734Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the '브랜드' column as the index in both DataFrames\n",
    "train_data.set_index('브랜드', inplace=True)\n",
    "brand_keyword.set_index('브랜드', inplace=True)\n",
    "\n",
    "# Update column names of 'brand_keyword' DataFrame to match the 'train_data' DataFrame\n",
    "brand_keyword.columns = [col + '_keyword' for col in brand_keyword.columns]\n",
    "\n",
    "# Merge the two DataFrames on the index ('브랜드')\n",
    "combined_df = pd.merge(train_data, brand_keyword, left_index=True, right_index=True)\n",
    "\n",
    "# Make a copy of the merged DataFrame and drop the 'ID' column\n",
    "train_data = combined_df.copy().drop('ID', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T04:29:57.226673Z",
     "start_time": "2023-08-03T04:29:57.222591Z"
    }
   },
   "outputs": [],
   "source": [
    "# combined_df = pd.merge(train_data, brand_keyword, on='브랜드', suffixes=('_sales', '_keyword'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T04:29:57.386062Z",
     "start_time": "2023-08-03T04:29:57.382427Z"
    }
   },
   "outputs": [],
   "source": [
    "# combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T04:30:13.924118Z",
     "start_time": "2023-08-03T04:30:13.920345Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_data = combined_df.copy().drop('ID', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T04:30:21.264002Z",
     "start_time": "2023-08-03T04:30:21.234219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>대분류</th>\n",
       "      <th>중분류</th>\n",
       "      <th>소분류</th>\n",
       "      <th>2022-01-01</th>\n",
       "      <th>2022-01-02</th>\n",
       "      <th>2022-01-03</th>\n",
       "      <th>2022-01-04</th>\n",
       "      <th>2022-01-05</th>\n",
       "      <th>2022-01-06</th>\n",
       "      <th>2022-01-07</th>\n",
       "      <th>...</th>\n",
       "      <th>2023-03-26_keyword</th>\n",
       "      <th>2023-03-27_keyword</th>\n",
       "      <th>2023-03-28_keyword</th>\n",
       "      <th>2023-03-29_keyword</th>\n",
       "      <th>2023-03-30_keyword</th>\n",
       "      <th>2023-03-31_keyword</th>\n",
       "      <th>2023-04-01_keyword</th>\n",
       "      <th>2023-04-02_keyword</th>\n",
       "      <th>2023-04-03_keyword</th>\n",
       "      <th>2023-04-04_keyword</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>브랜드</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B002-00001</th>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0007</td>\n",
       "      <td>B002-C003-0038</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31911</td>\n",
       "      <td>0.39164</td>\n",
       "      <td>0.37713</td>\n",
       "      <td>0.49318</td>\n",
       "      <td>0.07252</td>\n",
       "      <td>0.29010</td>\n",
       "      <td>0.31911</td>\n",
       "      <td>0.23208</td>\n",
       "      <td>0.33362</td>\n",
       "      <td>0.44966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B002-00002</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.26979</td>\n",
       "      <td>11.96692</td>\n",
       "      <td>10.64693</td>\n",
       "      <td>10.41485</td>\n",
       "      <td>10.48738</td>\n",
       "      <td>9.48651</td>\n",
       "      <td>9.28343</td>\n",
       "      <td>10.42935</td>\n",
       "      <td>11.15462</td>\n",
       "      <td>11.38671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B002-00002</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.26979</td>\n",
       "      <td>11.96692</td>\n",
       "      <td>10.64693</td>\n",
       "      <td>10.41485</td>\n",
       "      <td>10.48738</td>\n",
       "      <td>9.48651</td>\n",
       "      <td>9.28343</td>\n",
       "      <td>10.42935</td>\n",
       "      <td>11.15462</td>\n",
       "      <td>11.38671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B002-00002</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.26979</td>\n",
       "      <td>11.96692</td>\n",
       "      <td>10.64693</td>\n",
       "      <td>10.41485</td>\n",
       "      <td>10.48738</td>\n",
       "      <td>9.48651</td>\n",
       "      <td>9.28343</td>\n",
       "      <td>10.42935</td>\n",
       "      <td>11.15462</td>\n",
       "      <td>11.38671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B002-00003</th>\n",
       "      <td>B002-C001-0001</td>\n",
       "      <td>B002-C002-0001</td>\n",
       "      <td>B002-C003-0003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53669</td>\n",
       "      <td>0.69625</td>\n",
       "      <td>0.44966</td>\n",
       "      <td>0.39164</td>\n",
       "      <td>1.02988</td>\n",
       "      <td>0.49318</td>\n",
       "      <td>0.91383</td>\n",
       "      <td>0.79779</td>\n",
       "      <td>1.01537</td>\n",
       "      <td>0.88482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B002-03799</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0042</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.10588</td>\n",
       "      <td>6.67246</td>\n",
       "      <td>6.44038</td>\n",
       "      <td>5.90368</td>\n",
       "      <td>4.93182</td>\n",
       "      <td>5.51203</td>\n",
       "      <td>3.52480</td>\n",
       "      <td>4.03249</td>\n",
       "      <td>5.88917</td>\n",
       "      <td>5.07687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B002-03799</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.10588</td>\n",
       "      <td>6.67246</td>\n",
       "      <td>6.44038</td>\n",
       "      <td>5.90368</td>\n",
       "      <td>4.93182</td>\n",
       "      <td>5.51203</td>\n",
       "      <td>3.52480</td>\n",
       "      <td>4.03249</td>\n",
       "      <td>5.88917</td>\n",
       "      <td>5.07687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B002-03799</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.10588</td>\n",
       "      <td>6.67246</td>\n",
       "      <td>6.44038</td>\n",
       "      <td>5.90368</td>\n",
       "      <td>4.93182</td>\n",
       "      <td>5.51203</td>\n",
       "      <td>3.52480</td>\n",
       "      <td>4.03249</td>\n",
       "      <td>5.88917</td>\n",
       "      <td>5.07687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B002-03799</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.10588</td>\n",
       "      <td>6.67246</td>\n",
       "      <td>6.44038</td>\n",
       "      <td>5.90368</td>\n",
       "      <td>4.93182</td>\n",
       "      <td>5.51203</td>\n",
       "      <td>3.52480</td>\n",
       "      <td>4.03249</td>\n",
       "      <td>5.88917</td>\n",
       "      <td>5.07687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B002-03799</th>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0004</td>\n",
       "      <td>B002-C003-0020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.10588</td>\n",
       "      <td>6.67246</td>\n",
       "      <td>6.44038</td>\n",
       "      <td>5.90368</td>\n",
       "      <td>4.93182</td>\n",
       "      <td>5.51203</td>\n",
       "      <td>3.52480</td>\n",
       "      <td>4.03249</td>\n",
       "      <td>5.88917</td>\n",
       "      <td>5.07687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15890 rows × 921 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       대분류             중분류             소분류  2022-01-01  \\\n",
       "브랜드                                                                      \n",
       "B002-00001  B002-C001-0002  B002-C002-0007  B002-C003-0038           0   \n",
       "B002-00002  B002-C001-0003  B002-C002-0008  B002-C003-0044           0   \n",
       "B002-00002  B002-C001-0003  B002-C002-0008  B002-C003-0044           0   \n",
       "B002-00002  B002-C001-0003  B002-C002-0008  B002-C003-0044           0   \n",
       "B002-00003  B002-C001-0001  B002-C002-0001  B002-C003-0003           0   \n",
       "...                    ...             ...             ...         ...   \n",
       "B002-03799  B002-C001-0003  B002-C002-0008  B002-C003-0042           0   \n",
       "B002-03799  B002-C001-0003  B002-C002-0008  B002-C003-0044           0   \n",
       "B002-03799  B002-C001-0003  B002-C002-0008  B002-C003-0044           0   \n",
       "B002-03799  B002-C001-0003  B002-C002-0008  B002-C003-0044           0   \n",
       "B002-03799  B002-C001-0002  B002-C002-0004  B002-C003-0020           0   \n",
       "\n",
       "            2022-01-02  2022-01-03  2022-01-04  2022-01-05  2022-01-06  \\\n",
       "브랜드                                                                      \n",
       "B002-00001           0           0           0           0           0   \n",
       "B002-00002           0           0           0           0           0   \n",
       "B002-00002           0           0           0           0           0   \n",
       "B002-00002           0           0           0           0           0   \n",
       "B002-00003           0           0           0           0           0   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "B002-03799           0           0           0           0           0   \n",
       "B002-03799           0           0           0           0           0   \n",
       "B002-03799           0           0           0           0           0   \n",
       "B002-03799           0           0           0           0           0   \n",
       "B002-03799           0           0           0           0           0   \n",
       "\n",
       "            2022-01-07  ...  2023-03-26_keyword  2023-03-27_keyword  \\\n",
       "브랜드                     ...                                           \n",
       "B002-00001           0  ...             0.31911             0.39164   \n",
       "B002-00002           0  ...            10.26979            11.96692   \n",
       "B002-00002           0  ...            10.26979            11.96692   \n",
       "B002-00002           0  ...            10.26979            11.96692   \n",
       "B002-00003           0  ...             0.53669             0.69625   \n",
       "...                ...  ...                 ...                 ...   \n",
       "B002-03799           0  ...             5.10588             6.67246   \n",
       "B002-03799           0  ...             5.10588             6.67246   \n",
       "B002-03799           0  ...             5.10588             6.67246   \n",
       "B002-03799           0  ...             5.10588             6.67246   \n",
       "B002-03799           0  ...             5.10588             6.67246   \n",
       "\n",
       "            2023-03-28_keyword  2023-03-29_keyword  2023-03-30_keyword  \\\n",
       "브랜드                                                                      \n",
       "B002-00001             0.37713             0.49318             0.07252   \n",
       "B002-00002            10.64693            10.41485            10.48738   \n",
       "B002-00002            10.64693            10.41485            10.48738   \n",
       "B002-00002            10.64693            10.41485            10.48738   \n",
       "B002-00003             0.44966             0.39164             1.02988   \n",
       "...                        ...                 ...                 ...   \n",
       "B002-03799             6.44038             5.90368             4.93182   \n",
       "B002-03799             6.44038             5.90368             4.93182   \n",
       "B002-03799             6.44038             5.90368             4.93182   \n",
       "B002-03799             6.44038             5.90368             4.93182   \n",
       "B002-03799             6.44038             5.90368             4.93182   \n",
       "\n",
       "            2023-03-31_keyword  2023-04-01_keyword  2023-04-02_keyword  \\\n",
       "브랜드                                                                      \n",
       "B002-00001             0.29010             0.31911             0.23208   \n",
       "B002-00002             9.48651             9.28343            10.42935   \n",
       "B002-00002             9.48651             9.28343            10.42935   \n",
       "B002-00002             9.48651             9.28343            10.42935   \n",
       "B002-00003             0.49318             0.91383             0.79779   \n",
       "...                        ...                 ...                 ...   \n",
       "B002-03799             5.51203             3.52480             4.03249   \n",
       "B002-03799             5.51203             3.52480             4.03249   \n",
       "B002-03799             5.51203             3.52480             4.03249   \n",
       "B002-03799             5.51203             3.52480             4.03249   \n",
       "B002-03799             5.51203             3.52480             4.03249   \n",
       "\n",
       "            2023-04-03_keyword  2023-04-04_keyword  \n",
       "브랜드                                                 \n",
       "B002-00001             0.33362             0.44966  \n",
       "B002-00002            11.15462            11.38671  \n",
       "B002-00002            11.15462            11.38671  \n",
       "B002-00002            11.15462            11.38671  \n",
       "B002-00003             1.01537             0.88482  \n",
       "...                        ...                 ...  \n",
       "B002-03799             5.88917             5.07687  \n",
       "B002-03799             5.88917             5.07687  \n",
       "B002-03799             5.88917             5.07687  \n",
       "B002-03799             5.88917             5.07687  \n",
       "B002-03799             5.88917             5.07687  \n",
       "\n",
       "[15890 rows x 921 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T04:41:35.655819Z",
     "start_time": "2023-08-03T04:33:18.625072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ab966f947748f7a6c0d0d6cf84049e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15890 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Scaling\n",
    "scale_max_dict = {}\n",
    "scale_min_dict = {}\n",
    "\n",
    "for idx in tqdm(range(len(train_data))):\n",
    "    maxi = np.max(train_data.iloc[idx,4:])\n",
    "    mini = np.min(train_data.iloc[idx,4:])\n",
    "    \n",
    "    if maxi == mini :\n",
    "        train_data.iloc[idx,4:] = 0\n",
    "    else:\n",
    "        train_data.iloc[idx,4:] = (train_data.iloc[idx,4:] - mini) / (maxi - mini)\n",
    "    \n",
    "    scale_max_dict[idx] = maxi\n",
    "    scale_min_dict[idx] = mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T04:45:42.338208Z",
     "start_time": "2023-08-03T04:45:40.797962Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'브랜드'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/data/program_files/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/data/program_files/anaconda3/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/data/program_files/anaconda3/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '브랜드'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m categorical_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m대분류\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m중분류\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m소분류\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m브랜드\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m categorical_columns:\n\u001b[0;32m----> 6\u001b[0m     label_encoder\u001b[38;5;241m.\u001b[39mfit(\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      7\u001b[0m     train_data[col] \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mtransform(train_data[col])\n",
      "File \u001b[0;32m/data/program_files/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/data/program_files/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: '브랜드'"
     ]
    }
   ],
   "source": [
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = ['대분류', '중분류', '소분류', '브랜드']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    label_encoder.fit(train_data[col])\n",
    "    train_data[col] = label_encoder.transform(train_data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T04:17:19.554833Z",
     "start_time": "2023-08-03T04:17:19.547440Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['대분류', '중분류', '소분류', '브랜드', '2022-01-01_sales', '2022-01-02_sales',\n",
       "       '2022-01-03_sales', '2022-01-04_sales', '2022-01-05_sales',\n",
       "       '2022-01-06_sales',\n",
       "       ...\n",
       "       '2023-03-26_keyword', '2023-03-27_keyword', '2023-03-28_keyword',\n",
       "       '2023-03-29_keyword', '2023-03-30_keyword', '2023-03-31_keyword',\n",
       "       '2023-04-01_keyword', '2023-04-02_keyword', '2023-04-03_keyword',\n",
       "       '2023-04-04_keyword'],\n",
       "      dtype='object', length=922)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T04:20:37.183428Z",
     "start_time": "2023-08-03T04:20:37.171600Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_train_data(data, train_size=CFG['TRAIN_WINDOW_SIZE'], predict_size=CFG['PREDICT_SIZE']):\n",
    "    '''\n",
    "    학습 기간 블럭, 예측 기간 블럭의 세트로 데이터를 생성\n",
    "    data : 일별 판매량, 브랜드, 그리고 브랜드 키워드 카운트 정보가 있는 데이터 프레임\n",
    "    train_size : 학습에 활용할 기간\n",
    "    predict_size : 추론할 기간\n",
    "    '''\n",
    "    num_rows = len(data)\n",
    "    keyword_start_index = data.columns.get_loc('2022-01-01_keyword')  # Find the index of the first '2022-01-01_keyword' column\n",
    "    window_size = train_size + predict_size\n",
    "    \n",
    "    input_data = np.empty((num_rows * (len(data.columns) - window_size + 1), train_size, 6)) # 6 features: 대분류, 중분류, 소분류, 브랜드, sales, keyword count\n",
    "    target_data = np.empty((num_rows * (len(data.columns) - window_size + 1), predict_size))\n",
    "    \n",
    "    for i in tqdm(range(num_rows)):\n",
    "        encode_info = np.array(data.iloc[i, :4])  # Extract encoding info ('대분류', '중분류', '소분류', '브랜드')\n",
    "        sales_data = np.array(data.iloc[i, 4:])\n",
    "        keyword_data = np.array(data.iloc[i, keyword_start_index:])\n",
    "        \n",
    "        for j in range(len(sales_data) - window_size + 1):\n",
    "            window = sales_data[j : j + window_size]\n",
    "            temp_data = np.column_stack((encode_info, window[:train_size], keyword_data[j : j + window_size][:train_size]))\n",
    "            input_data[i * (len(data.columns) - window_size + 1) + j] = temp_data\n",
    "            target_data[i * (len(data.columns) - window_size + 1) + j] = window[train_size:]\n",
    "    \n",
    "    return input_data, target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T04:20:37.665254Z",
     "start_time": "2023-08-03T04:20:37.658035Z"
    }
   },
   "outputs": [],
   "source": [
    "# 확인 완료\n",
    "\n",
    "def make_predict_data(data, train_size=CFG['TRAIN_WINDOW_SIZE']):\n",
    "    '''\n",
    "    평가 데이터(Test Dataset)를 추론하기 위한 Input 데이터를 생성\n",
    "    data : 일별 판매량, 브랜드, 그리고 브랜드 키워드 카운트 정보가 있는 데이터 프레임\n",
    "    train_size : 추론을 위해 필요한 일별 판매량 기간 (= 학습에 활용할 기간)\n",
    "    '''\n",
    "    num_rows = len(data)\n",
    "    keyword_start_index = data.columns.get_loc('2022-01-01_keyword')  # Find the index of the first '2022-01-01_keyword' column\n",
    "    \n",
    "    input_data = np.empty((num_rows, train_size, 6))\n",
    "    \n",
    "    for i in tqdm(range(num_rows)):\n",
    "        encode_info = np.array(data.iloc[i, :4])  # Extract encoding info ('대분류', '중분류', '소분류', '브랜드')\n",
    "        sales_data = np.array(data.iloc[i, 4:4+train_size])  # Extract daily sales data for the past 'train_size' days\n",
    "        keyword_data = np.array(data.iloc[i, keyword_start_index:keyword_start_index+train_size])  # Extract keyword count data for the past 'train_size' days\n",
    "        \n",
    "        temp_data = np.column_stack((encode_info, sales_data, keyword_data))\n",
    "        input_data[i] = temp_data\n",
    "    \n",
    "    return input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T04:20:38.233136Z",
     "start_time": "2023-08-03T04:20:38.050918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35938809e9994c239e7a8d0896955a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15890 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 90 and the array at index 2 has size 89",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_input, train_target \u001b[38;5;241m=\u001b[39m \u001b[43mmake_train_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m test_input \u001b[38;5;241m=\u001b[39m make_predict_data(train_data)\n",
      "Cell \u001b[0;32mIn[32], line 17\u001b[0m, in \u001b[0;36mmake_train_data\u001b[0;34m(data, train_size, predict_size)\u001b[0m\n\u001b[1;32m     15\u001b[0m window \u001b[38;5;241m=\u001b[39m sales_data[j : j \u001b[38;5;241m+\u001b[39m window_size]\n\u001b[1;32m     16\u001b[0m keyword_slice \u001b[38;5;241m=\u001b[39m keyword_data[j : j \u001b[38;5;241m+\u001b[39m window_size]\n\u001b[0;32m---> 17\u001b[0m temp_data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencode_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeyword_slice\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m input_data[i \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m-\u001b[39m window_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m j] \u001b[38;5;241m=\u001b[39m temp_data\n\u001b[1;32m     19\u001b[0m target_data[i \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m-\u001b[39m window_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m j] \u001b[38;5;241m=\u001b[39m window[train_size: train_size \u001b[38;5;241m+\u001b[39m predict_size]\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mcolumn_stack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/data/program_files/anaconda3/lib/python3.10/site-packages/numpy/lib/shape_base.py:656\u001b[0m, in \u001b[0;36mcolumn_stack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    654\u001b[0m         arr \u001b[38;5;241m=\u001b[39m array(arr, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ndmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    655\u001b[0m     arrays\u001b[38;5;241m.\u001b[39mappend(arr)\n\u001b[0;32m--> 656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 90 and the array at index 2 has size 89"
     ]
    }
   ],
   "source": [
    "train_input, train_target = make_train_data(train_data)\n",
    "test_input = make_predict_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_35236/2996555914.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Train / Validation Split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mval_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_len\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mval_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_len\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_len\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_input' is not defined"
     ]
    }
   ],
   "source": [
    "# Train / Validation Split\n",
    "data_len = len(train_input)\n",
    "val_input = train_input[-int(data_len*0.2):]\n",
    "val_target = train_target[-int(data_len*0.2):]\n",
    "train_input = train_input[:-int(data_len*0.2)]\n",
    "train_target = train_target[:-int(data_len*0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4487336, 90, 5),\n",
       " (4487336, 21),\n",
       " (1121834, 90, 5),\n",
       " (1121834, 21),\n",
       " (15890, 90, 5))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape, train_target.shape, val_input.shape, val_target.shape, test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.Y is not None:\n",
    "            return torch.Tensor(self.X[index]), torch.Tensor(self.Y[index])\n",
    "        return torch.Tensor(self.X[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_input, train_target)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = CustomDataset(val_input, val_target)\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, input_size=5, hidden_size=512, output_size=CFG['PREDICT_SIZE']):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden_size//2, output_size)\n",
    "        )\n",
    "            \n",
    "        self.actv = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (B, TRAIN_WINDOW_SIZE, 5)\n",
    "        batch_size = x.size(0)\n",
    "        hidden = self.init_hidden(batch_size, x.device)\n",
    "        \n",
    "        # LSTM layer\n",
    "        lstm_out, hidden = self.lstm(x, hidden)\n",
    "        \n",
    "        # Only use the last output sequence\n",
    "        last_output = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Fully connected layer\n",
    "        output = self.actv(self.fc(last_output))\n",
    "        \n",
    "        return output.squeeze(1)\n",
    "    \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        # Initialize hidden state and cell state\n",
    "        return (torch.zeros(1, batch_size, self.hidden_size, device=device),\n",
    "                torch.zeros(1, batch_size, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    best_loss = 9999999\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        train_mae = []\n",
    "        for X, Y in tqdm(iter(train_loader)):\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(X)\n",
    "            loss = criterion(output, Y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "        val_loss = validation(model, val_loader, criterion, device)\n",
    "        print(f'Epoch : [{epoch}] Train Loss : [{np.mean(train_loss):.5f}] Val Loss : [{val_loss:.5f}]')\n",
    "        \n",
    "        if best_loss > val_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model = model\n",
    "            print('Model Saved')\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, Y in tqdm(iter(val_loader)):\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            \n",
    "            output = model(X)\n",
    "            loss = criterion(output, Y)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "    return np.mean(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1096 [00:00<?, ?it/s]  0%|          | 0/1096 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 14747697152 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7640/3377345380.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCFG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"LEARNING_RATE\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0minfer_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7640/1997222721.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, train_loader, val_loader, device)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pysung\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7640/461338738.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m# LSTM layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m# Only use the last output sequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pysung\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pysung\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    810\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[0;32m    813\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0;32m    814\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 14747697152 bytes."
     ]
    }
   ],
   "source": [
    "model = BaseModel()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
